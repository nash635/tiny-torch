# Tiny-Torch Docker Development Environment

æœ¬ç›®å½•åŒ…å«äº†Tiny-Torché¡¹ç›®çš„Dockerå¼€å‘ç¯å¢ƒé…ç½®ï¼Œæ”¯æŒGPUï¼ˆCUDA 12.9.1ï¼‰å’ŒCPUä¸¤ç§å¼€å‘æ¨¡å¼ï¼Œå†…ç½®PyTorch 2.7.1æ”¯æŒã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. æ„å»ºDockeré•œåƒ

```bash
# æ„å»ºæ‰€æœ‰é•œåƒï¼ˆæ¨èï¼‰
./docker/build.sh all

# ä»…æ„å»ºCPUç‰ˆæœ¬
./docker/build.sh cpu

# ä»…æ„å»ºGPUç‰ˆæœ¬ï¼ˆéœ€è¦NVIDIA Dockeræ”¯æŒï¼‰
./docker/build.sh gpu
```

### 2. å¯åŠ¨å¼€å‘ç¯å¢ƒ

```bash
# ä½¿ç”¨ç»Ÿä¸€çš„build.shè„šæœ¬ï¼ˆæ¨èï¼‰
./docker/build.sh dev-cpu     # å¯åŠ¨CPUå¼€å‘ç¯å¢ƒ
./docker/build.sh dev-gpu     # å¯åŠ¨GPUå¼€å‘ç¯å¢ƒ

# æˆ–ç›´æ¥ä½¿ç”¨docker-compose
docker-compose run --rm tiny-torch-cpu
docker-compose run --rm tiny-torch-dev
```

### 3. è¿è¡Œæµ‹è¯•

```bash
# æµ‹è¯•Dockerç¯å¢ƒ
./docker/build.sh test all

# åœ¨å®¹å™¨ä¸­æ„å»ºå’Œæµ‹è¯•é¡¹ç›®
./docker/build.sh project-build
./docker/build.sh project-test
```

## ğŸ“¦ ç¯å¢ƒé…ç½®

### GPUç‰ˆæœ¬ (tiny-torch:dev)
- **åŸºç¡€é•œåƒ**: nvidia/cuda:12.9.1-devel-ubuntu22.04
- **CUDAç‰ˆæœ¬**: 12.9.1
- **PyTorchç‰ˆæœ¬**: 2.7.1 (with CUDA 12.9 support)
- **Pythonç‰ˆæœ¬**: 3.10+
- **GPUè¿è¡Œæ—¶**: éœ€è¦NVIDIA Docker runtime

### CPUç‰ˆæœ¬ (tiny-torch:cpu)
- **åŸºç¡€é•œåƒ**: ubuntu:22.04
- **PyTorchç‰ˆæœ¬**: 2.7.1 (CPU only)
- **Pythonç‰ˆæœ¬**: 3.10+
- **ç”¨é€”**: æ— GPUæœåŠ¡å™¨å¼€å‘

### é¢„è£…è½¯ä»¶åŒ…

#### Pythonæ ¸å¿ƒåº“
- PyTorch 2.7.1 + torchvision + torchaudio
- NumPy, typing-extensions
- pybind11 (ç”¨äºC++ç»‘å®š)

#### å¼€å‘å·¥å…·
- CMake, Ninja Build
- pytest, pytest-cov (æµ‹è¯•æ¡†æ¶)
- black, flake8, mypy (ä»£ç è´¨é‡)
- pre-commit, isort (ä»£ç æ ¼å¼åŒ–)

#### å®ç”¨å·¥å…·
- Jupyter Notebook + IPython
- Git, vim, htop, tree
- å®Œæ•´çš„C++ç¼–è¯‘å·¥å…·é“¾

## ğŸ› ï¸ å¼€å‘å·¥ä½œæµ

### 1. æ—¥å¸¸å¼€å‘

```bash
# å¯åŠ¨å¼€å‘ç¯å¢ƒ
./docker/build.sh dev-cpu

# åœ¨å®¹å™¨å†…
cd /workspace
make install          # æ„å»ºé¡¹ç›®
make test             # è¿è¡Œæµ‹è¯•
python -c "import torch; print(torch.__version__)"
```

### 2. Jupyterå¼€å‘

```bash
# å¯åŠ¨Jupyter Notebook
./docker/build.sh jupyter-cpu    # CPUç‰ˆæœ¬
./docker/build.sh jupyter-gpu    # GPUç‰ˆæœ¬

# è®¿é—® http://localhost:8888
```

### 3. ä»£ç è°ƒè¯•

```bash
# è¿›å…¥å®¹å™¨Shell
./docker/build.sh shell

# åœ¨å®¹å™¨å†…ä½¿ç”¨å¼€å‘å·¥å…·
pytest test/                  # è¿è¡Œæµ‹è¯•
black .                      # ä»£ç æ ¼å¼åŒ–
mypy torch/                  # ç±»å‹æ£€æŸ¥
```

## ğŸ“‹ æ„å»ºå’Œæµ‹è¯•è¯´æ˜

### è‡ªåŠ¨åŒ–æ„å»º

1. **æ„å»ºDockeré•œåƒ**:
   ```bash
   cd /path/to/tiny-torch
   ./docker/build.sh build all
   ```

2. **éªŒè¯æ„å»º**:
   ```bash
   ./docker/build.sh test all
   ```

3. **å¯åŠ¨å¼€å‘**:
   ```bash
   ./docker/build.sh dev-cpu
   ```

### æ‰‹åŠ¨æµ‹è¯•æ­¥éª¤

#### ç¯å¢ƒæµ‹è¯•
```bash
# 1. æµ‹è¯•Pythonç¯å¢ƒ
docker-compose run --rm tiny-torch-cpu python --version

# 2. æµ‹è¯•PyTorchå®‰è£…
docker-compose run --rm tiny-torch-cpu python -c "
import torch
print(f'PyTorch version: {torch.__version__}')
print(f'CUDA available: {torch.cuda.is_available()}')
"

# 3. æµ‹è¯•åŸºæœ¬tensoræ“ä½œ
docker-compose run --rm tiny-torch-cpu python -c "
import torch
x = torch.randn(3, 3)
y = torch.randn(3, 3)
z = torch.matmul(x, y)
print(f'Matrix multiplication result shape: {z.shape}')
"
```

#### é¡¹ç›®æ„å»ºæµ‹è¯•
```bash
# 1. æ£€æŸ¥é¡¹ç›®ç»“æ„
docker-compose run --rm tiny-torch-cpu ls -la /workspace

# 2. æµ‹è¯•æ„å»ºç³»ç»Ÿ
docker-compose run --rm tiny-torch-cpu bash -c "
cd /workspace
python3 tools/diagnose_build.py
"

# 3. å°è¯•æ„å»ºé¡¹ç›®
docker-compose run --rm tiny-torch-cpu bash -c "
cd /workspace
make clean
make install
"

# 4. è¿è¡Œé¡¹ç›®æµ‹è¯•
docker-compose run --rm tiny-torch-cpu bash -c "
cd /workspace
make test
"
```

#### å¼€å‘å·¥å…·æµ‹è¯•
```bash
# 1. æµ‹è¯•CMake
docker-compose run --rm tiny-torch-cpu cmake --version

# 2. æµ‹è¯•C++ç¼–è¯‘å™¨
docker-compose run --rm tiny-torch-cpu g++ --version

# 3. æµ‹è¯•Pythonå¼€å‘å·¥å…·
docker-compose run --rm tiny-torch-cpu python -c "
import pytest, black, mypy, pybind11
print('All development tools available')
"

# 4. æµ‹è¯•Jupyter
docker-compose run --rm tiny-torch-cpu jupyter --version
```

### GPUç‰¹å®šæµ‹è¯• (éœ€è¦GPUæœåŠ¡å™¨)

```bash
# 1. æµ‹è¯•NVIDIA runtime
docker run --rm --gpus all nvidia/cuda:12.9.1-base-ubuntu22.04 nvidia-smi

# 2. æµ‹è¯•PyTorch GPUæ”¯æŒ
docker-compose run --rm tiny-torch-dev python -c "
import torch
print(f'CUDA available: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'GPU count: {torch.cuda.device_count()}')
    print(f'Current GPU: {torch.cuda.current_device()}')
    print(f'GPU name: {torch.cuda.get_device_name()}')
"

# 3. æµ‹è¯•GPU tensoræ“ä½œ
docker-compose run --rm tiny-torch-dev python -c "
import torch
if torch.cuda.is_available():
    x = torch.randn(1000, 1000).cuda()
    y = torch.randn(1000, 1000).cuda()
    z = torch.matmul(x, y)
    print(f'GPU computation successful: {z.shape}')
else:
    print('GPU not available for testing')
"
```

## ğŸ”§ ç»Ÿä¸€ç®¡ç†è„šæœ¬

### `./docker/build.sh` - ç»Ÿä¸€ç®¡ç†è„šæœ¬

```bash
# æ„å»ºå‘½ä»¤
./docker/build.sh build [gpu|cpu|all]     # æ„å»ºDockeré•œåƒ

# å¼€å‘å‘½ä»¤
./docker/build.sh dev-cpu                 # å¯åŠ¨CPUå¼€å‘ç¯å¢ƒ
./docker/build.sh dev-gpu                 # å¯åŠ¨GPUå¼€å‘ç¯å¢ƒ
./docker/build.sh jupyter-cpu             # å¯åŠ¨Jupyter (CPU)
./docker/build.sh jupyter-gpu             # å¯åŠ¨Jupyter (GPU)
./docker/build.sh shell [cpu|gpu]         # æ‰“å¼€å®¹å™¨Shell

# é¡¹ç›®å‘½ä»¤
./docker/build.sh project-build           # æ„å»ºé¡¹ç›®
./docker/build.sh project-test            # è¿è¡Œé¡¹ç›®æµ‹è¯•

# æµ‹è¯•å‘½ä»¤
./docker/build.sh test [cpu|gpu|all]      # æµ‹è¯•ç¯å¢ƒ
./docker/build.sh test-python             # æµ‹è¯•Pythonç¯å¢ƒ
./docker/build.sh test-pytorch            # æµ‹è¯•PyTorchå®‰è£…
./docker/build.sh test-cuda               # æµ‹è¯•CUDAæ”¯æŒ
./docker/build.sh test-project            # æµ‹è¯•é¡¹ç›®åŠŸèƒ½

# å®ç”¨å‘½ä»¤
./docker/build.sh clean                   # æ¸…ç†å®¹å™¨å’Œé•œåƒ
./docker/build.sh logs [cpu|gpu]          # æŸ¥çœ‹å®¹å™¨æ—¥å¿—
./docker/build.sh status                  # æ˜¾ç¤ºçŠ¶æ€
./docker/build.sh help                    # æ˜¾ç¤ºå¸®åŠ©
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **GPUæ”¯æŒä¸å¯ç”¨**
   ```bash
   # æ£€æŸ¥NVIDIA Docker runtime
   docker run --rm --gpus all nvidia/cuda:12.9.1-base-ubuntu22.04 nvidia-smi
   
   # å¦‚æœå¤±è´¥ï¼Œå®‰è£…nvidia-container-runtime
   # å‚è€ƒ: https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html
   ```

2. **æ„å»ºå¤±è´¥**
   ```bash
   # æ¸…ç†å¹¶é‡æ–°æ„å»º
   ./docker/build.sh clean
   ./docker/build.sh build all
   ```

3. **æƒé™é—®é¢˜**
   ```bash
   # ç¡®ä¿è„šæœ¬å¯æ‰§è¡Œ
   chmod +x docker/*.sh
   ```

4. **ç½‘ç»œé—®é¢˜**
   ```bash
   # ä½¿ç”¨å›½å†…PyTorché•œåƒæºï¼ˆå¦‚éœ€è¦ï¼‰
   # ç¼–è¾‘ Dockerfile ä¸­çš„ pip install å‘½ä»¤
   pip3 install torch==2.7.0 -i https://pypi.tuna.tsinghua.edu.cn/simple/
   ```

### è°ƒè¯•æ¨¡å¼

```bash
# å¯ç”¨Dockeræ„å»ºè¯¦ç»†è¾“å‡º
DOCKER_BUILDKIT=0 docker build -f docker/Dockerfile -t tiny-torch:dev .

# æ£€æŸ¥å®¹å™¨å†…éƒ¨çŠ¶æ€
docker-compose run --rm tiny-torch-cpu bash -c "
echo 'Python version:' && python --version
echo 'PyTorch version:' && python -c 'import torch; print(torch.__version__)'
echo 'Working directory:' && pwd
echo 'Files:' && ls -la
"
```

## ğŸ“š è¿›é˜¶ä½¿ç”¨

### 1. æ•°æ®å·æŒ‚è½½

```yaml
# åœ¨docker-compose.ymlä¸­æ·»åŠ è‡ªå®šä¹‰å·
volumes:
  - ./data:/workspace/data
  - ~/.cache/pip:/home/tinytorch/.cache/pip
```

### 2. ç¯å¢ƒå˜é‡é…ç½®

```bash
# è®¾ç½®CUDAè®¾å¤‡
export CUDA_VISIBLE_DEVICES=0,1
docker-compose run --rm tiny-torch-dev

# è®¾ç½®å¼€å‘æ¨¡å¼
export TINY_TORCH_DEV=1
```

### 3. ç«¯å£æ˜ å°„

```bash
# æ˜ å°„é¢å¤–ç«¯å£ (TensorBoardç­‰)
docker-compose run -p 6006:6006 --rm tiny-torch-dev
```

### 4. IDEé›†æˆ

```bash
# VS Code Remote-Containers
# æ·»åŠ  .devcontainer/devcontainer.json é…ç½®

# PyCharm Professional
# é…ç½®Dockerä½œä¸ºè¿œç¨‹Pythonè§£é‡Šå™¨
```

## ğŸ“ å¼€å‘æ³¨æ„äº‹é¡¹

1. **æ•°æ®æŒä¹…åŒ–**: å®¹å™¨å†…çš„ `/workspace` ç›®å½•æŒ‚è½½åˆ°é¡¹ç›®æ ¹ç›®å½•ï¼Œæ•°æ®ä¼šæŒä¹…åŒ–
2. **GPUå†…å­˜**: GPUç‰ˆæœ¬é»˜è®¤ä½¿ç”¨æ‰€æœ‰å¯ç”¨GPUï¼Œå¯é€šè¿‡ç¯å¢ƒå˜é‡é™åˆ¶
3. **ç½‘ç»œç«¯å£**: Jupyteré»˜è®¤ä½¿ç”¨8888ç«¯å£ï¼ŒTensorBoardä½¿ç”¨6006ç«¯å£
4. **ç”¨æˆ·æƒé™**: å®¹å™¨å†…ä½¿ç”¨érootç”¨æˆ· `tinytorch` è¿è¡Œï¼Œé¿å…æƒé™é—®é¢˜
5. **ä¾èµ–æ›´æ–°**: å¦‚éœ€æ·»åŠ æ–°ä¾èµ–ï¼Œæ›´æ–°Dockerfileå¹¶é‡æ–°æ„å»ºé•œåƒ

## ğŸ¤ è´¡çŒ®

å¦‚éœ€æ”¹è¿›Dockerç¯å¢ƒé…ç½®ï¼Œè¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. ä¿®æ”¹ç›¸åº”çš„Dockerfileæˆ–è„šæœ¬
2. è¿è¡Œæµ‹è¯•: `./docker/test.sh`
3. æ›´æ–°æ–‡æ¡£
4. æäº¤Pull Request

---

**ä½œè€…**: Tiny-Torchå›¢é˜Ÿ  
**æ›´æ–°æ—¥æœŸ**: 2025å¹´6æœˆ  
**Dockerç‰ˆæœ¬è¦æ±‚**: 20.10+  
**nvidia-container-runtime**: 3.4.0+ (GPUæ”¯æŒ)
