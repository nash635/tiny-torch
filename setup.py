#!/usr/bin/env python3
"""
Setup script for Tiny-Torch
å‚è€ƒ pytorch/setup.py çš„å®žçŽ°
"""

import os
import sys
import subprocess
import platform
from pathlib import Path
from setuptools import setup, Extension, find_packages
from pybind11.setup_helpers import Pybind11Extension, build_ext
from pybind11 import get_cmake_dir
import pybind11
import shutil

# Project metadata
PACKAGE_NAME = "tiny-torch"
VERSION = "0.1.0"
DESCRIPTION = "A PyTorch-inspired deep learning framework"
AUTHOR = "Tiny-Torch Contributors"
EMAIL = "tiny-torch@example.com"
URL = "https://github.com/your-username/tiny-torch"

# Build configuration
DEBUG = os.getenv("DEBUG", "0") == "1"
WITH_CUDA = os.getenv("WITH_CUDA", "1") == "1"
WITH_MKL = os.getenv("WITH_MKL", "0") == "1"
WITH_OPENMP = os.getenv("WITH_OPENMP", "1") == "1"
VERBOSE = os.getenv("VERBOSE", "0") == "1"

# Paths
ROOT_DIR = Path(__file__).parent.absolute()
CSRC_DIR = ROOT_DIR / "csrc"
BUILD_DIR = ROOT_DIR / "build"

def test_ninja_compatibility():
    """æµ‹è¯•Ninjaæ˜¯å¦çœŸæ­£å¯ç”¨"""
    if not shutil.which("ninja"):
        return False
        
    try:
        # æµ‹è¯•ninjaç‰ˆæœ¬å‘½ä»¤
        result = subprocess.run(
            ["ninja", "--version"], 
            capture_output=True, 
            text=True, 
            check=True,
            timeout=5
        )
        version = result.stdout.strip()
        if VERBOSE:
            print(f"Ninja version: {version}")
        return True
    except (subprocess.CalledProcessError, subprocess.TimeoutExpired, FileNotFoundError):
        return False

def should_use_ninja():
    """æ™ºèƒ½åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨Ninja"""
    # æ£€æŸ¥çŽ¯å¢ƒå˜é‡è®¾ç½®
    if os.getenv("USE_NINJA", "1") == "0":
        return False
        
    # æ£€æŸ¥Ninjaå…¼å®¹æ€§
    if not test_ninja_compatibility():
        if VERBOSE:
            print("Ninja compatibility test failed, falling back to Make")
        return False
        
    return True

# è®¾ç½®USE_NINJAå˜é‡
USE_NINJA = should_use_ninja()

def setup_color_output():
    """è®¾ç½®å¼ºåˆ¶å½©è‰²è¾“å‡ºçš„çŽ¯å¢ƒå˜é‡"""
    # è®¾ç½®å„ç§å·¥å…·çš„å½©è‰²è¾“å‡ºçŽ¯å¢ƒå˜é‡
    color_env = {
        'FORCE_COLOR': '1',
        'CMAKE_COLOR_MAKEFILE': 'ON',
        'CMAKE_COLOR_DIAGNOSTICS': 'ON', 
        'CMAKE_FORCE_COLORED_OUTPUT': 'ON',
        'CLICOLOR_FORCE': '1',
        'NINJA_STATUS': '[%f/%t] ',
        # ä¸ºç¼–è¯‘å™¨è®¾ç½®å½©è‰²è¾“å‡º
        'CFLAGS': os.environ.get('CFLAGS', '') + ' -fdiagnostics-color=always',
        'CXXFLAGS': os.environ.get('CXXFLAGS', '') + ' -fdiagnostics-color=always',
    }
    
    # æ›´æ–°çŽ¯å¢ƒå˜é‡
    for key, value in color_env.items():
        os.environ[key] = value
    
    if VERBOSE:
        print("âœ… Enabled forced color output for build tools")

def check_env():
    """æ£€æŸ¥æž„å»ºçŽ¯å¢ƒ"""
    print("=== Tiny-Torch Build Environment ===")
    print(f"Python version: {sys.version}")
    print(f"Platform: {platform.platform()}")
    print(f"Architecture: {platform.machine()}")
    print(f"WITH_CUDA: {WITH_CUDA}")
    print(f"WITH_MKL: {WITH_MKL}")
    print(f"WITH_OPENMP: {WITH_OPENMP}")
    print(f"DEBUG: {DEBUG}")
    print(f"USE_NINJA: {USE_NINJA}")
    print("=====================================")

def get_sources():
    """èŽ·å–æ‰€æœ‰C++æºæ–‡ä»¶åˆ—è¡¨"""
    sources = [
        # Python API bindings
        "csrc/api/src/python_bindings.cpp",
        "csrc/api/src/tensor_api.cpp",
        "csrc/api/src/autograd_api.cpp",
        
        # ATen core
        "csrc/aten/src/ATen/core/Tensor.cpp",
        "csrc/aten/src/ATen/core/TensorImpl.cpp",
        "csrc/aten/src/ATen/core/Storage.cpp",
        "csrc/aten/src/ATen/core/Allocator.cpp",
        
        # Native operations
        "csrc/aten/src/ATen/native/BinaryOps.cpp",
        "csrc/aten/src/ATen/native/UnaryOps.cpp",
        "csrc/aten/src/ATen/native/LinearAlgebra.cpp",
        "csrc/aten/src/ATen/native/Activation.cpp",
        "csrc/aten/src/ATen/native/Reduction.cpp",
        
        # TH layer
        "csrc/aten/src/TH/THTensor.cpp",
        "csrc/aten/src/TH/THStorage.cpp",
        "csrc/aten/src/TH/THAllocator.cpp",
        
        # Autograd
        "csrc/autograd/engine.cpp",
        "csrc/autograd/function.cpp",
        "csrc/autograd/variable.cpp",
        "csrc/autograd/functions/basic_ops.cpp",
    ]
    
    if WITH_CUDA:
        cuda_sources = [
            "csrc/aten/src/ATen/cuda/CUDAContext.cu",
            "csrc/aten/src/ATen/native/cuda/BinaryOps.cu",
            "csrc/aten/src/ATen/native/cuda/UnaryOps.cu",
            "csrc/aten/src/ATen/native/cuda/LinearAlgebra.cu",
            "csrc/aten/src/ATen/native/cuda/Activation.cu",
            "csrc/aten/src/ATen/native/cuda/Reduction.cu",
        ]
        sources.extend(cuda_sources)
    
    return sources

def use_cmake_build():
    """æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨CMakeæž„å»º (å½“é¡¹ç›®å˜å¤æ‚æ—¶)"""
    # å½“æºæ–‡ä»¶æ•°é‡è¶…è¿‡é˜ˆå€¼æ—¶ï¼Œä½¿ç”¨CMake+ninjaæž„å»º
    sources = get_sources()
    return len(sources) > 20 or WITH_CUDA

def cmake_build():
    """ä½¿ç”¨CMake+ninjaæž„å»º"""
    print("Using CMake+ninja build system...")
    
    # è®¾ç½®å½©è‰²è¾“å‡º
    setup_color_output()
    
    # åˆ›å»ºæž„å»ºç›®å½•
    cmake_build_dir = BUILD_DIR / "cmake"
    cmake_build_dir.mkdir(parents=True, exist_ok=True)
    
    # CMakeé…ç½®å‘½ä»¤
    cmake_args = [
        f"-DCMAKE_BUILD_TYPE={'Debug' if DEBUG else 'Release'}",
        f"-DWITH_CUDA={'ON' if WITH_CUDA else 'OFF'}",
        f"-DWITH_MKL={'ON' if WITH_MKL else 'OFF'}",
        f"-DWITH_OPENMP={'ON' if WITH_OPENMP else 'OFF'}",
        f"-DCMAKE_INSTALL_PREFIX={ROOT_DIR}/tiny_torch",
    ]
    
    # ä½¿ç”¨ninjaå¦‚æžœå¯ç”¨
    if USE_NINJA:
        cmake_args.append("-GNinja")
        print("Using Ninja generator for faster builds")
    
    # è¿è¡ŒCMakeé…ç½®
    print(f"Running CMake configure in {cmake_build_dir}")
    try:
        result = subprocess.run([
            "cmake", str(ROOT_DIR), *cmake_args
        ], cwd=cmake_build_dir, capture_output=True, text=True, check=True)
        print("âœ… CMake configure successful")
        if VERBOSE:
            print(result.stdout)
    except subprocess.CalledProcessError as e:
        print(f"âŒ CMake configure failed: {e}")
        if e.stderr:
            print("Error output:", e.stderr)
        if e.stdout:
            print("Output:", e.stdout)
        return False
    
    # è¿è¡Œæž„å»º
    print("Running build...")
    try:
        if USE_NINJA:
            build_cmd = ["ninja"]
            if VERBOSE:
                build_cmd.append("-v")
        else:
            build_cmd = ["make", "-j"]
            if VERBOSE:
                build_cmd.append("VERBOSE=1")
                
        result = subprocess.run(build_cmd, cwd=cmake_build_dir, capture_output=True, text=True, check=True)
        print("âœ… Build successful")
        if VERBOSE:
            print(result.stdout)
    except subprocess.CalledProcessError as e:
        print(f"âŒ Build failed: {e}")
        if e.stderr:
            print("Error output:", e.stderr)
        if e.stdout:
            print("Output:", e.stdout)
        
        # å¦‚æžœNinjaå¤±è´¥ï¼Œå°è¯•é™çº§åˆ°Make
        if USE_NINJA:
            print("ðŸ”„ Ninja build failed, trying fallback to Make...")
            try:
                # é‡æ–°é…ç½®ä½¿ç”¨Make
                cmake_args_make = [arg for arg in cmake_args if not arg.startswith("-GNinja")]
                subprocess.run([
                    "cmake", str(ROOT_DIR), *cmake_args_make
                ], cwd=cmake_build_dir, check=True)
                
                # ç”¨Makeæž„å»º
                subprocess.run(["make", "-j"], cwd=cmake_build_dir, check=True)
                print("âœ… Make fallback build successful")
            except subprocess.CalledProcessError as fallback_e:
                print(f"âŒ Make fallback also failed: {fallback_e}")
                return False
        else:
            return False
    
    print("CMake build completed successfully!")
    return True

def get_cuda_version():
    """èŽ·å–CUDAç‰ˆæœ¬"""
    try:
        result = subprocess.run(
            ["nvcc", "--version"], 
            capture_output=True, 
            text=True, 
            check=True
        )
        for line in result.stdout.split('\n'):
            if 'release' in line:
                version = line.split('release')[1].split(',')[0].strip()
                return version
    except (subprocess.CalledProcessError, FileNotFoundError):
        return None
    return None

def use_cmake_build():
    """æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨CMakeæž„å»º (å½“é¡¹ç›®å˜å¤æ‚æ—¶)"""
    # å½“æºæ–‡ä»¶æ•°é‡è¶…è¿‡é˜ˆå€¼æ—¶ï¼Œä½¿ç”¨CMake+ninjaæž„å»º
    sources = get_sources()
    return len(sources) > 20 or WITH_CUDA

def cmake_build():
    """ä½¿ç”¨CMake+ninjaæž„å»º"""
    print("Using CMake+ninja build system...")
    
    # è®¾ç½®å½©è‰²è¾“å‡º
    setup_color_output()
    
    # åˆ›å»ºæž„å»ºç›®å½•
    cmake_build_dir = BUILD_DIR / "cmake"
    cmake_build_dir.mkdir(parents=True, exist_ok=True)
    
    # CMakeé…ç½®å‘½ä»¤
    cmake_args = [
        f"-DCMAKE_BUILD_TYPE={'Debug' if DEBUG else 'Release'}",
        f"-DWITH_CUDA={'ON' if WITH_CUDA else 'OFF'}",
        f"-DWITH_MKL={'ON' if WITH_MKL else 'OFF'}",
        f"-DWITH_OPENMP={'ON' if WITH_OPENMP else 'OFF'}",
        f"-DCMAKE_INSTALL_PREFIX={ROOT_DIR}/tiny_torch",
    ]
    
    # ä½¿ç”¨ninjaå¦‚æžœå¯ç”¨
    if USE_NINJA:
        cmake_args.append("-GNinja")
        print("Using Ninja generator for faster builds")
    
    # è¿è¡ŒCMakeé…ç½®
    subprocess.run([
        "cmake", str(ROOT_DIR), *cmake_args
    ], cwd=cmake_build_dir, check=True)
    
    # è¿è¡Œæž„å»º
    if USE_NINJA:
        subprocess.run(["ninja"], cwd=cmake_build_dir, check=True)
    else:
        subprocess.run(["make", "-j"], cwd=cmake_build_dir, check=True)
    
    print("CMake build completed successfully!")

def get_extensions():
    """èŽ·å–æ‰©å±•æ¨¡å—é…ç½®"""
    global WITH_CUDA  # Declare as global to avoid UnboundLocalError
    extensions = []
    
    # æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨CMakeæž„å»º
    if use_cmake_build():
        print("Complex project detected, using CMake+ninja build system")
        # å¯¹äºŽå¤æ‚é¡¹ç›®ï¼Œæˆ‘ä»¬ä»ç„¶è¿”å›žsetuptoolsæ‰©å±•ï¼Œä½†ä¸»è¦å·¥ä½œç”±CMakeå®Œæˆ
        # è¿™æ˜¯ä¸€ä¸ªè¿‡æ¸¡æ–¹æ¡ˆï¼Œç¡®ä¿setuptoolsä»èƒ½æ­£ç¡®å¤„ç†ç”Ÿæˆçš„åº“
        pass
    
    # èŽ·å–æºæ–‡ä»¶åˆ—è¡¨
    sources = get_sources()
    
    # CUDAæºæ–‡ä»¶ - æš‚æ—¶ç¦ç”¨ä»¥ä½¿ç”¨CMakeæž„å»ºCUDAä»£ç 
    # TODO: åœ¨Phase 1.2ä¸­å®žçŽ°CUDAæ”¯æŒçš„Pythonç»‘å®š
    # if WITH_CUDA:
    #     cuda_sources = [
    #         "csrc/aten/src/ATen/cuda/CUDAContext.cu",
    #         "csrc/aten/src/ATen/native/cuda/BinaryOps.cu",
    #         "csrc/aten/src/ATen/native/cuda/UnaryOps.cu",
    #         "csrc/aten/src/ATen/native/cuda/LinearAlgebra.cu",
    #         "csrc/aten/src/ATen/native/cuda/Activation.cu",
    #         "csrc/aten/src/ATen/native/cuda/Reduction.cu",
    #     ]
    #     sources.extend(cuda_sources)
    
    # åŒ…å«ç›®å½•
    include_dirs = [
        str(CSRC_DIR),
        str(CSRC_DIR / "api" / "include"),
        str(CSRC_DIR / "aten" / "include"),
        pybind11.get_include(),
    ]
    
    # ç¼–è¯‘å™¨é€‰é¡¹
    cxx_flags = ["-std=c++17", "-fPIC"]
    if DEBUG:
        cxx_flags.extend(["-g", "-O0", "-DDEBUG"])
    else:
        cxx_flags.extend(["-O3", "-DNDEBUG"])
    
    # Linux ç³»ç»Ÿç‰¹å®šé€‰é¡¹
    if platform.system() == "Linux":
        cxx_flags.extend(["-Wall", "-Wextra"])
    else:
        raise RuntimeError(f"Unsupported platform: {platform.system()}. Only Linux is supported.")
    
    # é“¾æŽ¥åº“
    libraries = []
    library_dirs = []
    
    # CUDAæ”¯æŒ
    if WITH_CUDA:
        cuda_version = get_cuda_version()
        if cuda_version:
            print(f"Found CUDA version: {cuda_version}")
            cxx_flags.append("-DWITH_CUDA")
            
            # CUDAè·¯å¾„
            cuda_home = os.environ.get("CUDA_HOME", "/usr/local/cuda")
            include_dirs.append(f"{cuda_home}/include")
            library_dirs.append(f"{cuda_home}/lib64")
            
            # CUDAåº“
            libraries.extend(["cudart", "cublas", "curand"])
            
            # å°è¯•æ‰¾åˆ°cuDNN
            cudnn_lib_dir = f"{cuda_home}/lib64"
            if os.path.exists(f"{cudnn_lib_dir}/libcudnn.so"):
                libraries.append("cudnn")
        else:
            print("CUDA requested but nvcc not found, disabling CUDA")
            WITH_CUDA = False
    
    # OpenMPæ”¯æŒ - ä»…é™ Linux
    if WITH_OPENMP:
        cxx_flags.append("-DWITH_OPENMP")
        cxx_flags.append("-fopenmp")
        libraries.append("gomp")
    
    # BLAS/LAPACK æ”¯æŒ - ä½¿ç”¨æ›´çµæ´»çš„æ–¹æ³•
    if WITH_MKL:
        mkl_root = os.environ.get("MKLROOT")
        if mkl_root:
            cxx_flags.append("-DWITH_MKL")
            include_dirs.append(f"{mkl_root}/include")
            library_dirs.append(f"{mkl_root}/lib/intel64")
            libraries.extend(["mkl_intel_lp64", "mkl_sequential", "mkl_core"])
        else:
            print("MKL requested but MKLROOT not set, skipping BLAS/LAPACK")
    else:
        # å°è¯•æ‰¾åˆ°BLAS/LAPACKä½†ä¸å¼ºåˆ¶è¦æ±‚
        print("Warning: Building without BLAS/LAPACK libraries, tensor operations will be CPU-only")
    
    # åˆ›å»ºæ‰©å±•
    ext = Pybind11Extension(
        "tiny_torch._C",
        sources=sources,
        include_dirs=include_dirs,
        libraries=libraries,
        library_dirs=library_dirs,
        cxx_std=17,
        extra_compile_args=cxx_flags,
    )
    
    extensions.append(ext)
    return extensions

def get_requirements():
    """è¯»å–ä¾èµ–"""
    requirements = []
    req_file = ROOT_DIR / "requirements.txt"
    if req_file.exists():
        with open(req_file, 'r') as f:
            requirements = [line.strip() for line in f if line.strip() and not line.startswith('#')]
    return requirements

def get_long_description():
    """è¯»å–é•¿æè¿°"""
    readme_file = ROOT_DIR / "README.md"
    if readme_file.exists():
        with open(readme_file, 'r', encoding='utf-8') as f:
            return f.read()
    return DESCRIPTION

class CustomBuildExt(build_ext):
    """è‡ªå®šä¹‰æž„å»ºç±»"""
    
    def build_extensions(self):
        # è®¾ç½®ç¼–è¯‘å™¨é€‰é¡¹
        if self.compiler.compiler_type == 'unix':
            for ext in self.extensions:
                # æ·»åŠ -fvisibility=hiddenä»¥å‡å°‘ç¬¦å·æš´éœ²
                ext.extra_compile_args.append('-fvisibility=hidden')
        
        super().build_extensions()
    
    def run(self):
        # è®¾ç½®å½©è‰²è¾“å‡º
        setup_color_output()
        
        # ç¡®ä¿æž„å»ºç›®å½•å­˜åœ¨
        BUILD_DIR.mkdir(exist_ok=True)
        super().run()

if __name__ == "__main__":
    check_env()
    
    # å¦‚æžœæºæ–‡ä»¶è¾ƒå¤šæˆ–éœ€è¦CUDAæ”¯æŒï¼Œä½¿ç”¨CMakeæž„å»º
    if use_cmake_build():
        cmake_build()

# Setup configuration (always available for pip)
setup(
    name=PACKAGE_NAME,
    version=VERSION,
    description=DESCRIPTION,
    long_description=get_long_description(),
    long_description_content_type="text/markdown",
    author=AUTHOR,
    author_email=EMAIL,
    url=URL,
    
    packages=find_packages(exclude=["test*", "benchmarks*"]),
    ext_modules=get_extensions() if not use_cmake_build() else [],
    cmdclass={"build_ext": CustomBuildExt},
    
    # Dependencies are now managed in pyproject.toml to avoid duplication
    # install_requires=get_requirements(),  # Commented out to avoid setuptools warning
    python_requires=">=3.8",
    
    classifiers=[
        "Development Status :: 3 - Alpha",
        "Intended Audience :: Developers",
        "Intended Audience :: Science/Research",
        "License :: OSI Approved :: BSD License",
        "Operating System :: POSIX :: Linux",
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3.8",
        "Programming Language :: Python :: 3.9",
        "Programming Language :: Python :: 3.10",
        "Programming Language :: Python :: 3.11",
        "Topic :: Scientific/Engineering :: Artificial Intelligence",
    ],
    
    zip_safe=False,
    include_package_data=True,
)
