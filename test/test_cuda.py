#!/usr/bin/env python3
"""
test_cuda_comprehensive.py
Tiny-Torch CUDAåŠŸèƒ½ç»¼åˆæµ‹è¯•å¥—ä»¶

åˆå¹¶äº†åŸæœ‰çš„å¤šä¸ªCUDAæµ‹è¯•æ–‡ä»¶ï¼Œæä¾›ç»Ÿä¸€çš„æµ‹è¯•æ¥å£ã€‚
"""

import subprocess
import sys
import os
import time
import argparse
from pathlib import Path

# åŠ¨æ€è·å–é¡¹ç›®æ ¹ç›®å½•è·¯å¾„
PROJECT_ROOT = Path(__file__).parent.parent.resolve()
sys.path.insert(0, str(PROJECT_ROOT))

def run_environment_tests():
    """è¿è¡Œç¯å¢ƒæµ‹è¯•"""
    print("ğŸ“‹ ç³»ç»Ÿç¯å¢ƒæµ‹è¯•")
    print("-" * 30)
    
    results = {}
    
    # æµ‹è¯•CUDAé©±åŠ¨
    print("ğŸ” æ£€æµ‹NVIDIA GPUé©±åŠ¨...")
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… NVIDIA GPUæ£€æµ‹æˆåŠŸ")
            lines = result.stdout.split('\n')[:3]
            for line in lines:
                if line.strip():
                    print(f"   {line}")
            results['CUDAé©±åŠ¨'] = True
        else:
            print("âŒ nvidia-smiå‘½ä»¤å¤±è´¥")
            results['CUDAé©±åŠ¨'] = False
    except:
        print("âŒ nvidia-smiå‘½ä»¤æœªæ‰¾åˆ°")
        results['CUDAé©±åŠ¨'] = False
    
    # æµ‹è¯•CUDAç¼–è¯‘å™¨
    print("\nğŸ” æ£€æµ‹CUDAç¼–è¯‘å™¨...")
    try:
        result = subprocess.run(['nvcc', '--version'], capture_output=True, text=True)
        if result.returncode == 0:
            print("âœ… CUDAç¼–è¯‘å™¨(nvcc)å¯ç”¨")
            lines = result.stdout.split('\n')
            for line in lines:
                if 'release' in line.lower():
                    print(f"   {line.strip()}")
            results['CUDAç¼–è¯‘å™¨'] = True
        else:
            print("âŒ nvccç¼–è¯‘å™¨ä¸å¯ç”¨")
            results['CUDAç¼–è¯‘å™¨'] = False
    except:
        print("âŒ nvccç¼–è¯‘å™¨æœªæ‰¾åˆ°")
        results['CUDAç¼–è¯‘å™¨'] = False
    
    # æµ‹è¯•GPUå±æ€§
    print("\nğŸ” æŸ¥è¯¢GPUè®¾å¤‡ä¿¡æ¯...")
    try:
        result = subprocess.run([
            'nvidia-smi', '--query-gpu=gpu_name,memory.total,compute_cap', 
            '--format=csv,noheader,nounits'
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            print("âœ… GPUè®¾å¤‡ä¿¡æ¯:")
            lines = result.stdout.strip().split('\n')
            for i, line in enumerate(lines):
                if line.strip():
                    parts = line.split(', ')
                    if len(parts) >= 3:
                        name, memory, compute_cap = parts[0], parts[1], parts[2]
                        print(f"   GPU {i}: {name}")
                        print(f"   å†…å­˜: {memory}MB, è®¡ç®—èƒ½åŠ›: {compute_cap}")
            results['GPUå±æ€§'] = True
        else:
            print("âŒ æ— æ³•è·å–GPUè®¾å¤‡ä¿¡æ¯")
            results['GPUå±æ€§'] = False
    except:
        print("âŒ GPUä¿¡æ¯æŸ¥è¯¢å¤±è´¥")
        results['GPUå±æ€§'] = False
    
    return results

def run_functional_tests():
    """è¿è¡ŒåŠŸèƒ½æµ‹è¯•"""
    print("ğŸ“‹ åŸºæœ¬åŠŸèƒ½æµ‹è¯•")
    print("-" * 30)
    
    results = {}
    
    # æµ‹è¯•tiny_torchå¯¼å…¥
    print("ğŸ” æµ‹è¯•tiny_torchæ¨¡å—å¯¼å…¥...")
    try:
        import tiny_torch
        print(f"âœ… å¯¼å…¥tiny_torchæˆåŠŸï¼Œç‰ˆæœ¬: {tiny_torch.__version__}")
        results['tiny_torchå¯¼å…¥'] = True
    except ImportError as e:
        print(f"âŒ æ— æ³•å¯¼å…¥tiny_torch: {e}")
        results['tiny_torchå¯¼å…¥'] = False
        return results
    
    # æµ‹è¯•CUDAæ¨¡å—
    print("\nğŸ” æµ‹è¯•tiny_torch.cudaæ¨¡å—...")
    try:
        if hasattr(tiny_torch, 'cuda'):
            print("âœ… tiny_torch.cudaæ¨¡å—å­˜åœ¨")
            
            # æ£€æŸ¥åŸºæœ¬å‡½æ•°
            functions = ['is_available', 'device_count', 'current_device', 'get_device_name']
            all_exist = True
            for func in functions:
                if hasattr(tiny_torch.cuda, func):
                    print(f"   âœ“ {func}")
                else:
                    print(f"   âœ— {func} ç¼ºå¤±")
                    all_exist = False
            
            results['cudaæ¨¡å—'] = all_exist
        else:
            print("âŒ tiny_torch.cudaæ¨¡å—ä¸å­˜åœ¨")
            results['cudaæ¨¡å—'] = False
    except Exception as e:
        print(f"âŒ æµ‹è¯•tiny_torch.cudaæ¨¡å—å¤±è´¥: {e}")
        results['cudaæ¨¡å—'] = False
    
    # æµ‹è¯•CUDAåŠŸèƒ½
    print("\nğŸ” æµ‹è¯•CUDAåŸºæœ¬åŠŸèƒ½...")
    try:
        if tiny_torch.cuda.is_available():
            print(f"âœ… CUDAå¯ç”¨æ€§: {tiny_torch.cuda.is_available()}")
            print(f"âœ… è®¾å¤‡æ•°é‡: {tiny_torch.cuda.device_count()}")
            print(f"âœ… å½“å‰è®¾å¤‡: {tiny_torch.cuda.current_device()}")
            
            # æµ‹è¯•è®¾å¤‡ä¿¡æ¯
            for i in range(tiny_torch.cuda.device_count()):
                name = tiny_torch.cuda.get_device_name(i)
                props = tiny_torch.cuda.get_device_properties(i)
                print(f"âœ… GPU {i}: {name}")
                if props:
                    total_mem = props.get('total_memory', 0)
                    compute_cap = props.get('compute_capability', 'Unknown')
                    print(f"   å†…å­˜: {total_mem // (1024**3)} GB, è®¡ç®—èƒ½åŠ›: {compute_cap}")
            
            results['CUDAåŠŸèƒ½'] = True
        else:
            print("âš ï¸  CUDAä¸å¯ç”¨")
            results['CUDAåŠŸèƒ½'] = False
    except Exception as e:
        print(f"âŒ CUDAåŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        results['CUDAåŠŸèƒ½'] = False
    
    return results

def run_build_tests():
    """è¿è¡Œæ„å»ºæµ‹è¯•"""
    print("ğŸ“‹ æ„å»ºç³»ç»Ÿæµ‹è¯•")
    print("-" * 30)
    
    results = {}
    
    # æ£€æŸ¥CMakeé…ç½®
    print("ğŸ” æ£€æŸ¥CMake CUDAé…ç½®...")
    cmake_file = PROJECT_ROOT / "CMakeLists.txt"
    if cmake_file.exists():
        with open(cmake_file, 'r') as f:
            content = f.read()
        
        checks = [
            ("WITH_CUDAé€‰é¡¹", "WITH_CUDA" in content),
            ("CUDAè¯­è¨€æ”¯æŒ", "enable_language(CUDA)" in content),
            ("CUDAToolkitæŸ¥æ‰¾", "find_package(CUDAToolkit" in content),
        ]
        
        print("âœ… CMake CUDAé…ç½®æ£€æŸ¥:")
        all_passed = True
        for check_name, passed in checks:
            status = "âœ“" if passed else "âœ—"
            print(f"   {status} {check_name}")
            if not passed:
                all_passed = False
        
        results['CMakeé…ç½®'] = all_passed
    else:
        print("âŒ CMakeLists.txtæ–‡ä»¶ä¸å­˜åœ¨")
        results['CMakeé…ç½®'] = False
    
    # æ£€æŸ¥CUDAæºæ–‡ä»¶
    print("\nğŸ” æ£€æŸ¥CUDAæºæ–‡ä»¶...")
    cuda_files = [
        "csrc/aten/src/ATen/cuda/CUDAContext.cu",
        "csrc/aten/src/ATen/native/cuda/BinaryOps.cu",
        "csrc/aten/src/ATen/native/cuda/UnaryOps.cu",
    ]
    
    all_exist = True
    for cuda_file in cuda_files:
        full_path = PROJECT_ROOT / cuda_file
        if full_path.exists():
            print(f"   âœ“ {cuda_file}")
        else:
            print(f"   âœ— {cuda_file}")
            all_exist = False
    
    results['æºæ–‡ä»¶'] = all_exist
    
    # æ£€æŸ¥æ„å»ºäº§ç‰©
    print("\nğŸ” æ£€æŸ¥æ„å»ºäº§ç‰©...")
    # æŸ¥æ‰¾å¯èƒ½çš„æ„å»ºç›®å½•å’Œé™æ€åº“
    possible_lib_paths = [
        PROJECT_ROOT / "build" / "cmake" / "libtiny_torch_cpp.a",  # æ ‡å‡†æ„å»ºç›®å½•
        PROJECT_ROOT / "build" / "libtiny_torch_cpp.a"            # å¤‡ç”¨ä½ç½®
    ]
    
    lib_found = False
    for lib_file in possible_lib_paths:
        if lib_file.exists():
            lib_size = lib_file.stat().st_size
            print(f"   âœ“ é™æ€åº“: {lib_size // 1024} KB ({lib_file.relative_to(PROJECT_ROOT)})")
            results['æ„å»ºäº§ç‰©'] = True
            lib_found = True
            break
    
    if not lib_found:
        print("   âœ— é™æ€åº“æ–‡ä»¶ä¸å­˜åœ¨")
        results['æ„å»ºäº§ç‰©'] = False
    
    return results

def run_demo():
    """è¿è¡Œæ¼”ç¤º"""
    print("ğŸ“‹ åŠŸèƒ½æ¼”ç¤º")
    print("-" * 30)
    
    try:
        import tiny_torch
        
        print(f"ğŸ“¦ Tiny-Torchç‰ˆæœ¬: {tiny_torch.__version__}")
        print(f"ğŸ”§ CUDAå¯ç”¨æ€§: {tiny_torch.cuda.is_available()}")
        
        if tiny_torch.cuda.is_available():
            print(f"ğŸ® GPUè®¾å¤‡æ•°é‡: {tiny_torch.cuda.device_count()}")
            print(f"ğŸ¯ å½“å‰è®¾å¤‡: {tiny_torch.cuda.current_device()}")
            print(f"ğŸ“Š CUDAç‰ˆæœ¬: {tiny_torch.cuda.version()}")
            
            print("\nğŸ“‹ GPUè®¾å¤‡è¯¦ç»†ä¿¡æ¯:")
            for i in range(tiny_torch.cuda.device_count()):
                name = tiny_torch.cuda.get_device_name(i)
                props = tiny_torch.cuda.get_device_properties(i)
                print(f"   GPU {i}: {name}")
                if props:
                    print(f"     å†…å­˜: {props['total_memory'] // (1024**3)} GB")
                    print(f"     è®¡ç®—èƒ½åŠ›: {props['compute_capability']}")
        else:
            print("âš ï¸  CUDAå½“å‰ä¸å¯ç”¨")
            
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Tiny-Torch CUDAç»¼åˆæµ‹è¯•å¥—ä»¶')
    parser.add_argument('--basic', action='store_true', help='åªè¿è¡ŒåŸºæœ¬åŠŸèƒ½æµ‹è¯•')
    parser.add_argument('--demo', action='store_true', help='åªè¿è¡ŒåŠŸèƒ½æ¼”ç¤º')
    parser.add_argument('--build', action='store_true', help='åªè¿è¡Œæ„å»ºç³»ç»Ÿæµ‹è¯•')
    parser.add_argument('--env', action='store_true', help='åªè¿è¡Œç¯å¢ƒæµ‹è¯•')
    
    args = parser.parse_args()
    
    print("ğŸ¯ Tiny-Torch CUDAç»¼åˆæµ‹è¯•å¥—ä»¶")
    print("=" * 60)
    print(f"æµ‹è¯•æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)
    
    all_results = {}
    
    # æ ¹æ®å‚æ•°é€‰æ‹©è¦è¿è¡Œçš„æµ‹è¯•
    run_all = not any([args.basic, args.demo, args.build, args.env])
    
    if args.env or run_all:
        env_results = run_environment_tests()
        all_results.update(env_results)
        print()
    
    if args.basic or run_all:
        func_results = run_functional_tests()
        all_results.update(func_results)
        print()
    
    if args.build or run_all:
        build_results = run_build_tests()
        all_results.update(build_results)
        print()
    
    if args.demo or run_all:
        run_demo()
        print()
    
    # æµ‹è¯•ç»“æœæ€»ç»“
    if all_results:
        print("=" * 60)
        print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
        print("=" * 60)
        
        passed = 0
        for test_name, result in all_results.items():
            status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
            print(f"   {test_name:12}: {status}")
            if result:
                passed += 1
        
        total = len(all_results)
        print(f"\nğŸ¯ æ€»ä½“ç»“æœ: {passed}/{total} æµ‹è¯•é€šè¿‡ ({passed/total*100:.1f}%)")
        
        if passed >= total * 0.8:
            print("\nâœ… CUDAæ”¯æŒè‰¯å¥½ï¼")
            print("   ğŸš€ å·²ä¸ºPhase 1.2åšå¥½å‡†å¤‡")
            return True
        else:
            print("\nâš ï¸  CUDAæ”¯æŒéœ€è¦æ”¹è¿›")
            return False
    
    return True

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
