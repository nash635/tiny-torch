# Memory Debug Tools for Tiny Torch
# æ˜¾å­˜è°ƒè¯•å·¥å…·é›†

è¿™æ˜¯ä¸€å¥—ä¸“ä¸º Tiny Torch è®¾è®¡çš„æ˜¾å­˜è°ƒè¯•å·¥å…·ï¼Œå¸®åŠ©å¼€å‘è€…æ’æŸ¥å’Œè§£å†³åˆ†å¸ƒå¼è®­ç»ƒä¸­çš„æ˜¾å­˜é—®é¢˜ã€‚

## ğŸ¯ ä¸»è¦åŠŸèƒ½

### ç»Ÿä¸€æ¥å£
- **MemoryDebugger**: ç»Ÿä¸€çš„è°ƒè¯•æ¥å£ï¼Œæ•´åˆæ‰€æœ‰åŠŸèƒ½
- **å‘½ä»¤è¡Œå·¥å…·**: æ”¯æŒ `python -m tools.memory` è°ƒç”¨
- **ç®€åŒ–é…ç½®**: å¼€ç®±å³ç”¨ï¼Œæœ€å°åŒ–é…ç½®

### æ ¸å¿ƒåŠŸèƒ½
1. **æ˜¾å­˜åˆ†æ** - å®æ—¶ç›‘æ§GPUæ˜¾å­˜ä½¿ç”¨æƒ…å†µï¼Œç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
2. **OOMæ£€æµ‹** - æ™ºèƒ½é¢„è­¦ç³»ç»Ÿï¼Œé¢„æµ‹OOMå‘ç”Ÿæ—¶é—´
3. **å†…å­˜æ³„æ¼æ£€æµ‹** - æ£€æµ‹æ˜¾å­˜å’ŒPythonå†…å­˜æ³„æ¼
4. **ç¢ç‰‡åˆ†æ** - åˆ†ææ˜¾å­˜ç¢ç‰‡åŒ–ç¨‹åº¦ï¼ˆåŸºç¡€ç‰ˆæœ¬ï¼‰
5. **åˆ†å¸ƒå¼ç›‘æ§** - è·¨èŠ‚ç‚¹æ˜¾å­˜ä½¿ç”¨åè°ƒç›‘æ§ï¼ˆæ‰©å±•åŠŸèƒ½ï¼‰

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–
```bash
pip install numpy matplotlib psutil
# æˆ–è€…
pip install -r requirements.txt
```

### Python API ä½¿ç”¨

#### 1. ç»Ÿä¸€æ¥å£ï¼ˆæ¨èï¼‰
```python
from tools.memory import MemoryDebugger

# å¯åŠ¨å…¨é¢ç›‘æ§
debugger = MemoryDebugger()
debugger.start_monitoring()

# è®­ç»ƒä»£ç ...
# your_training_code()

# åœæ­¢ç›‘æ§å¹¶è·å–æŠ¥å‘Š
debugger.stop_monitoring()
report = debugger.get_status_report()
print(f"ç›‘æ§æ‘˜è¦: {report}")
```

#### 2. å•ç‹¬ä½¿ç”¨å„å·¥å…·
```python
from tools.memory import MemoryProfiler, OOMDetector

# å†…å­˜åˆ†æ
profiler = MemoryProfiler(sampling_interval=0.1)
profiler.start_monitoring()
# ... è¿è¡Œä¸€æ®µæ—¶é—´å
profiler.stop_monitoring()
profiler.generate_report('memory_report.json')

# OOMæ£€æµ‹
detector = OOMDetector(threshold=85.0)
detector.start_monitoring()
# ... è‡ªåŠ¨é¢„è­¦
```

### å‘½ä»¤è¡Œä½¿ç”¨

#### 1. å†…å­˜åˆ†æ
```bash
# ç›‘æ§60ç§’å¹¶ç”ŸæˆæŠ¥å‘Š
python -m tools.memory profile --duration 60 --output profile.json

# æŒç»­ç›‘æ§ç‰¹å®šGPU
python -m tools.memory profile --devices 0 1 --duration 0
```

#### 2. OOMç›‘æ§
```bash
# 85%é˜ˆå€¼OOMç›‘æ§
python -m tools.memory oom --threshold 85 --monitor

# ç›‘æ§ç‰¹å®šè®¾å¤‡
python -m tools.memory oom --devices 0 --threshold 90
```

#### 3. å†…å­˜æ³„æ¼æ£€æµ‹
```bash
# æ£€æŸ¥å†…å­˜æ³„æ¼
python -m tools.memory leak --check --threshold 100
```

#### 4. å…¨é¢ç›‘æ§
```bash
# å¯åŠ¨æ‰€æœ‰ç›‘æ§åŠŸèƒ½
python -m tools.memory monitor --all

# ç›‘æ§æŒ‡å®šæ—¶é•¿
python -m tools.memory monitor --all --duration 300
```

## ğŸ“Š è¾“å‡ºç¤ºä¾‹

### å†…å­˜çŠ¶æ€æŠ¥å‘Š
```json
{
  "timestamp": "2025-01-15T10:30:00",
  "devices": {
    "0": {
      "current_usage": {
        "allocated": 8589934592,
        "free": 3758096384,
        "total": 12348030976,
        "utilization_percent": 69.5
      },
      "statistics": {
        "avg_utilization": 65.2,
        "max_utilization": 89.1,
        "samples_count": 600
      }
    }
  },
  "summary": {
    "total_devices": 1,
    "total_memory_gb": 11.5,
    "overall_utilization": 69.5
  }
}
```

### OOMé¢„è­¦ç¤ºä¾‹
```
âš ï¸  OOMè­¦å‘Š: GPU 0
   é£é™©ç­‰çº§: high
   å½“å‰ä½¿ç”¨ç‡: 87.3%
   é¢„æµ‹OOMæ—¶é—´: 45.2ç§’å
   ç½®ä¿¡åº¦: 0.82
   å»ºè®®: å‡†å¤‡é‡Šæ”¾ç¼“å­˜
   å»ºè®®: è€ƒè™‘å‡å°‘batch size
```

## ğŸ”§ é«˜çº§é…ç½®

### è‡ªå®šä¹‰OOMå›è°ƒ
```python
def custom_oom_callback(prediction):
    if prediction.risk_level.value == "critical":
        # æ‰§è¡Œç´§æ€¥æ“ä½œï¼Œå¦‚å‡å°‘batch size
        print(f"Critical OOM risk on GPU {prediction.device_id}! Taking action...")
        # tiny_torch.cuda.empty_cache()
        # reduce_batch_size()

detector = OOMDetector(warning_callback=custom_oom_callback)
detector.start_monitoring()
```

### æ˜¾å­˜ä¼˜åŒ–ç­–ç•¥
1. **åŸºäºåˆ†æç»“æœè°ƒæ•´batch size**
2. **ä½¿ç”¨gradient checkpointingå‡å°‘å³°å€¼å†…å­˜**
3. **å®šæœŸæ¸…ç†CUDAç¼“å­˜**: `tiny_torch.cuda.empty_cache()`
4. **ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ**: å‡å°‘å†…å­˜ä½¿ç”¨
5. **ä¼˜åŒ–æ•°æ®åŠ è½½**: é¿å…æ•°æ®é¢„å¤„ç†å ç”¨è¿‡å¤šå†…å­˜

## ğŸ“‹ æŠ€æœ¯è¯´æ˜

### æ¶æ„è®¾è®¡
- **æ¨¡å—åŒ–è®¾è®¡**: æ¯ä¸ªåŠŸèƒ½ç‹¬ç«‹ï¼Œå¯å•ç‹¬ä½¿ç”¨
- **ç»Ÿä¸€æ¥å£**: MemoryDebugger æä¾›ä¸€ç«™å¼è§£å†³æ–¹æ¡ˆ
- **è½»é‡çº§**: æœ€å°åŒ–å¯¹è®­ç»ƒæ€§èƒ½çš„å½±å“
- **å¯æ‰©å±•**: æ”¯æŒè‡ªå®šä¹‰å›è°ƒå’Œç­–ç•¥

### ä¾èµ–è¯´æ˜
- **numpy**: æ•°å€¼è®¡ç®—å’Œç»Ÿè®¡åˆ†æ
- **matplotlib**: ç”Ÿæˆå†…å­˜ä½¿ç”¨å›¾è¡¨
- **psutil**: ç³»ç»Ÿè¿›ç¨‹ç›‘æ§
- **æ ‡å‡†åº“**: threading, json, subprocessç­‰

### æ€§èƒ½å½±å“
- é»˜è®¤é‡‡æ ·é—´éš”: 0.1ç§’ï¼ˆå¯è°ƒèŠ‚ï¼‰
- å†…å­˜å¼€é”€: æ¯è®¾å¤‡çº¦1-5MBå†å²æ•°æ®
- CPUå ç”¨: é€šå¸¸ < 1%

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜
1. **nvidia-smi ä¸å¯ç”¨**: æ£€æŸ¥NVIDIAé©±åŠ¨å®‰è£…
2. **å¯¼å…¥é”™è¯¯**: ç¡®ä¿å®‰è£…äº†æ‰€éœ€ä¾èµ–
3. **æƒé™é—®é¢˜**: æŸäº›ç³»ç»Ÿç›‘æ§åŠŸèƒ½éœ€è¦é€‚å½“æƒé™

### è°ƒè¯•æ¨¡å¼
```python
import logging
logging.basicConfig(level=logging.DEBUG)

debugger = MemoryDebugger()
debugger.start_monitoring()
```

## ğŸ“ ç‰ˆæœ¬å†å²

### v1.0.0
- æ•´åˆæ‰€æœ‰åŠŸèƒ½åˆ°å•ä¸€æ–‡ä»¶
- ç®€åŒ–APIå’Œå‘½ä»¤è¡Œæ¥å£
- ä¼˜åŒ–æ€§èƒ½å’Œç¨³å®šæ€§
- å®Œå–„æ–‡æ¡£å’Œç¤ºä¾‹

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Request æ¥æ”¹è¿›è¿™ä¸ªå·¥å…·é›†ã€‚

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®éµå¾ªä¸ Tiny Torch ä¸»é¡¹ç›®ç›¸åŒçš„è®¸å¯è¯ã€‚

# æŒ‡å®šç‰¹å®šGPUè®¾å¤‡
python memory_debug_cli.py profile --devices 0 1 --duration 120
```

#### 2. OOMé£é™©æ£€æµ‹
```bash
# 85%é˜ˆå€¼æŒç»­ç›‘æ§
python memory_debug_cli.py oom --threshold 85 --monitor

# å®šæ—¶ç›‘æ§300ç§’
python memory_debug_cli.py oom --threshold 80 --duration 300 --output oom_report.json
```

#### 3. å†…å­˜æ³„æ¼æ£€æµ‹
```bash
# å¯ç”¨å¼•ç”¨è·Ÿè¸ªï¼Œ10MB/minæ³„æ¼é˜ˆå€¼
python memory_debug_cli.py leak --threshold 10 --enable-tracking --duration 600

# è¾“å‡ºè¯¦ç»†æŠ¥å‘Š
python memory_debug_cli.py leak --output leak_report.json --duration 300
```

#### 4. ç¢ç‰‡åˆ†æ
```bash
# åˆ†æç¢ç‰‡åŒ–å¹¶ç”Ÿæˆå›¾è¡¨
python memory_debug_cli.py fragment --duration 120 --plot --output fragment.json

# æŒç»­ç›‘æ§ç¢ç‰‡åŒ–è¶‹åŠ¿
python memory_debug_cli.py fragment --duration 300 --interval 5.0
```

#### 5. åˆ†å¸ƒå¼ç›‘æ§
```bash
# å¯åŠ¨masterèŠ‚ç‚¹
python memory_debug_cli.py distributed --role master --port 29500

# å¯åŠ¨workerèŠ‚ç‚¹ï¼ˆè¿æ¥åˆ°masterï¼‰
python memory_debug_cli.py distributed --role worker --master-host 192.168.1.100 --port 29500
```

### äº¤äº’å¼æ¨¡å¼
```bash
# è¿›å…¥äº¤äº’å¼è°ƒè¯•æ¨¡å¼
python memory_debug_cli.py interactive
```

## ğŸ“Š ä½¿ç”¨åœºæ™¯

### åœºæ™¯1ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­é¢‘ç¹OOM
```bash
# 1. é¦–å…ˆåˆ†æå½“å‰å†…å­˜ä½¿ç”¨æ¨¡å¼
python memory_debug_cli.py profile --duration 60 --plot

# 2. å¯åŠ¨OOMæ£€æµ‹ï¼Œè®¾ç½®è¾ƒä½é˜ˆå€¼è¿›è¡Œé¢„è­¦
python memory_debug_cli.py oom --threshold 75 --monitor

# 3. å¦‚æœæ€€ç–‘å†…å­˜æ³„æ¼ï¼Œè¿è¡Œæ³„æ¼æ£€æµ‹
python memory_debug_cli.py leak --enable-tracking --duration 600
```

### åœºæ™¯2ï¼šæ˜¾å­˜ç¢ç‰‡å¯¼è‡´çš„æ€§èƒ½ä¸‹é™
```bash
# 1. åˆ†æç¢ç‰‡åŒ–ç¨‹åº¦
python memory_debug_cli.py fragment --duration 180 --plot

# 2. ç›‘æ§ç¢ç‰‡åŒ–è¶‹åŠ¿
python memory_debug_cli.py fragment --duration 600 --interval 10
```

### åœºæ™¯3ï¼šåˆ†å¸ƒå¼è®­ç»ƒè´Ÿè½½ä¸å‡è¡¡
```bash
# åœ¨masterèŠ‚ç‚¹ä¸Šå¯åŠ¨
python memory_debug_cli.py distributed --role master --duration 600

# åœ¨workerèŠ‚ç‚¹ä¸Šå¯åŠ¨
python memory_debug_cli.py distributed --role worker --master-host <master_ip>
```

## ğŸ”§ é«˜çº§ç”¨æ³•

### ç¼–ç¨‹æ¥å£ä½¿ç”¨

```python
from tools.memory import (
    MemoryProfiler, 
    OOMDetector, 
    FragmentationAnalyzer,
    MemoryLeakDetector,
    DistributedMemoryMonitor
)

# åˆ›å»ºå†…å­˜åˆ†æå™¨
profiler = MemoryProfiler(sampling_interval=1.0)
profiler.start_monitoring()

# è¿è¡Œè®­ç»ƒä»£ç 
# ... your training code ...

# åœæ­¢ç›‘æ§å¹¶ç”ŸæˆæŠ¥å‘Š
profiler.stop_monitoring()
report = profiler.generate_report("training_memory_report.json")
```

### è‡ªå®šä¹‰å›è°ƒå‡½æ•°

```python
def custom_oom_callback(device_id, prediction):
    if prediction.risk_level.value == "critical":
        # æ‰§è¡Œç´§æ€¥æ“ä½œï¼Œå¦‚å‡å°‘batch size
        print(f"Critical OOM risk on GPU {device_id}! Taking action...")
        # tiny_torch.cuda.empty_cache()
        # reduce_batch_size()

detector = OOMDetector()
detector.add_warning_callback(custom_oom_callback)
detector.start_monitoring()
```

## ğŸ“ˆ æŠ¥å‘Šæ ¼å¼

### å†…å­˜åˆ†ææŠ¥å‘Šç¤ºä¾‹
```json
{
  "timestamp": "2025-06-23T10:30:00",
  "devices": {
    "0": {
      "current_memory": {
        "allocated": 8589934592,
        "free": 2147483648,
        "total": 10737418240,
        "utilization": 80.0
      },
      "peak_memory": 9663676416,
      "statistics": {
        "avg_utilization": 75.5,
        "max_utilization": 95.2,
        "avg_fragmentation": 15.3,
        "num_snapshots": 3600
      }
    }
  }
}
```

### OOMé£é™©æŠ¥å‘Šç¤ºä¾‹
```json
{
  "devices": {
    "0": {
      "risk_assessment": {
        "risk_level": "high",
        "confidence": 0.8,
        "current_usage_percent": 88.5,
        "growth_rate_mb_per_sec": 12.3,
        "predicted_oom_time_seconds": 45,
        "recommendation": "Reduce batch size immediately"
      }
    }
  }
}
```

## âš¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### æ˜¾å­˜ä¼˜åŒ–ç­–ç•¥
1. **åŸºäºåˆ†æç»“æœè°ƒæ•´batch size**
2. **ä½¿ç”¨gradient checkpointingå‡å°‘å³°å€¼å†…å­˜**
3. **å®šæœŸæ¸…ç†CUDAç¼“å­˜**: `tiny_torch.cuda.empty_cache()`
4. **ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ**: å‡å°‘å†…å­˜ä½¿ç”¨
5. **ä¼˜åŒ–æ•°æ®åŠ è½½**: é¿å…æ•°æ®é¢„å¤„ç†å ç”¨è¿‡å¤šå†…å­˜

### ç¢ç‰‡åŒ–ä¼˜åŒ–
1. **é¿å…é¢‘ç¹çš„å°å—åˆ†é…é‡Šæ”¾**
2. **ä½¿ç”¨å†…å­˜æ± **: é¢„åˆ†é…å¤§å—å†…å­˜
3. **å®šæœŸç¢ç‰‡æ•´ç†**: åœ¨åˆé€‚çš„æ—¶æœºæ¸…ç†ç¼“å­˜
4. **ä¼˜åŒ–å¼ é‡ç”Ÿå‘½å‘¨æœŸ**: åŠæ—¶é‡Šæ”¾ä¸éœ€è¦çš„å¼ é‡

### åˆ†å¸ƒå¼ä¼˜åŒ–
1. **è´Ÿè½½å‡è¡¡**: æ ¹æ®ç›‘æ§ç»“æœè°ƒæ•´å„èŠ‚ç‚¹è´Ÿè½½
2. **åŒæ­¥ä¼˜åŒ–**: é¿å…å†…å­˜ä½¿ç”¨ä¸å‡è¡¡å¯¼è‡´çš„åŒæ­¥ç­‰å¾…
3. **æ•…éšœæ¢å¤**: åŸºäºç›‘æ§æ•°æ®å®ç°æ™ºèƒ½æ•…éšœæ¢å¤

## ğŸ” æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### 1. "nvidia-smi command not found"
- ç¡®ä¿å®‰è£…äº†NVIDIAé©±åŠ¨
- æ£€æŸ¥PATHç¯å¢ƒå˜é‡æ˜¯å¦åŒ…å«nvidia-smi

#### 2. ç›‘æ§æ•°æ®ä¸å‡†ç¡®
- æ£€æŸ¥GPUè®¾å¤‡æ˜¯å¦æ­£ç¡®è¯†åˆ«
- ç¡®è®¤ç›‘æ§è¿›ç¨‹æœ‰è¶³å¤Ÿæƒé™
- éªŒè¯é‡‡æ ·é—´éš”è®¾ç½®æ˜¯å¦åˆç†

#### 3. åˆ†å¸ƒå¼ç›‘æ§è¿æ¥å¤±è´¥
- æ£€æŸ¥ç½‘ç»œconnectivity
- ç¡®è®¤é˜²ç«å¢™è®¾ç½®
- éªŒè¯ç«¯å£æ˜¯å¦è¢«å ç”¨

#### 4. å†…å­˜æ³„æ¼è¯¯æŠ¥
- è°ƒæ•´æ³„æ¼æ£€æµ‹é˜ˆå€¼
- æ£€æŸ¥æ˜¯å¦æœ‰æ­£å¸¸çš„å†…å­˜å¢é•¿ï¼ˆå¦‚æ¨¡å‹æƒé‡æ›´æ–°ï¼‰
- å¯ç”¨å¼•ç”¨è·Ÿè¸ªè·å–è¯¦ç»†ä¿¡æ¯

## ğŸ“ æœ€ä½³å®è·µ

### 1. ç›‘æ§ç­–ç•¥
- **å¼€å‘é˜¶æ®µ**: ä½¿ç”¨è¾ƒçŸ­çš„é‡‡æ ·é—´éš”(1-2ç§’)è¿›è¡Œè¯¦ç»†åˆ†æ
- **ç”Ÿäº§ç¯å¢ƒ**: ä½¿ç”¨è¾ƒé•¿çš„é‡‡æ ·é—´éš”(5-10ç§’)é™ä½ç›‘æ§å¼€é”€
- **å…³é”®è®­ç»ƒ**: å¯ç”¨æ‰€æœ‰ç›‘æ§å·¥å…·è¿›è¡Œå…¨é¢åˆ†æ

### 2. æŠ¥å‘Šç®¡ç†
- å®šæœŸä¿å­˜ç›‘æ§æŠ¥å‘Šç”¨äºè¶‹åŠ¿åˆ†æ
- å»ºç«‹æŠ¥å‘Šå½’æ¡£æœºåˆ¶
- è®¾ç½®è‡ªåŠ¨åŒ–æŠ¥å‘Šç”Ÿæˆ

### 3. å‘Šè­¦é…ç½®
- æ ¹æ®æ¨¡å‹å’Œç¡¬ä»¶ç‰¹ç‚¹è°ƒæ•´å‘Šè­¦é˜ˆå€¼
- è®¾ç½®å¤šçº§å‘Šè­¦æœºåˆ¶
- é›†æˆåˆ°ç°æœ‰çš„ç›‘æ§ç³»ç»Ÿ

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç å’Œå»ºè®®ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Fork this repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ä¸Tiny-Torchç›¸åŒçš„è®¸å¯è¯ã€‚

## ğŸ™‹â€â™‚ï¸ æ”¯æŒ

å¦‚æœé‡åˆ°é—®é¢˜æˆ–æœ‰å»ºè®®ï¼Œè¯·ï¼š
1. æŸ¥çœ‹æœ¬æ–‡æ¡£çš„æ•…éšœæ’æŸ¥éƒ¨åˆ†
2. åœ¨GitHubä¸Šæäº¤Issue
3. è”ç³»é¡¹ç›®ç»´æŠ¤è€…

---

**æ³¨æ„**: è¿™äº›å·¥å…·ä¸»è¦ç”¨äºè°ƒè¯•å’Œåˆ†æï¼Œåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨æ—¶è¯·è¯„ä¼°æ€§èƒ½å½±å“ã€‚
