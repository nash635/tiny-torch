# Memory Debugging Tools for Distributed Training
# åˆ†å¸ƒå¼è®­ç»ƒæ˜¾å­˜è°ƒè¯•å·¥å…·é›†

è¿™æ˜¯ä¸€å¥—ä¸“ä¸ºåˆ†å¸ƒå¼è®­ç»ƒåœºæ™¯è®¾è®¡çš„æ˜¾å­˜è°ƒè¯•å·¥å…·ï¼Œå¸®åŠ©å¼€å‘è€…æ’æŸ¥å’Œè§£å†³å¸¸è§çš„æ˜¾å­˜é—®é¢˜ã€‚

## ğŸ¯ ä¸»è¦åŠŸèƒ½

### 1. æ˜¾å­˜åˆ†æå·¥å…· (Memory Profiler)
- **å®æ—¶æ˜¾å­˜ç›‘æ§**: æŒç»­ç›‘æ§GPUæ˜¾å­˜ä½¿ç”¨æƒ…å†µ
- **å³°å€¼è¿½è¸ª**: è®°å½•æ˜¾å­˜ä½¿ç”¨å³°å€¼ï¼Œå¸®åŠ©ä¼˜åŒ–å†…å­˜é…ç½®
- **ä½¿ç”¨çƒ­å›¾**: ç”Ÿæˆæ˜¾å­˜ä½¿ç”¨è¶‹åŠ¿å›¾è¡¨
- **è¯¦ç»†æŠ¥å‘Š**: è¾“å‡ºJSONæ ¼å¼çš„è¯¦ç»†åˆ†ææŠ¥å‘Š

### 2. OOMæ£€æµ‹å™¨ (OOM Detector)
- **æ™ºèƒ½é¢„è­¦**: åŸºäºè¶‹åŠ¿åˆ†æé¢„æµ‹OOMå‘ç”Ÿæ—¶é—´
- **é£é™©è¯„ä¼°**: å¤šçº§é£é™©è¯„ä¼°ï¼ˆä½/ä¸­/é«˜/ä¸¥é‡ï¼‰
- **è‡ªåŠ¨å»ºè®®**: æä¾›é’ˆå¯¹æ€§çš„ä¼˜åŒ–å»ºè®®
- **å®æ—¶ç›‘æ§**: æ”¯æŒæŒç»­ç›‘æ§æ¨¡å¼

### 3. æ˜¾å­˜ç¢ç‰‡åˆ†æå™¨ (Fragmentation Analyzer)
- **ç¢ç‰‡æ£€æµ‹**: åˆ†ææ˜¾å­˜ç¢ç‰‡åŒ–ç¨‹åº¦
- **åˆ†é…æ¨¡å¼åˆ†æ**: è¯†åˆ«å†…å­˜åˆ†é…æ¨¡å¼
- **æ•´ç†å»ºè®®**: æä¾›ç¢ç‰‡æ•´ç†å»ºè®®
- **è¶‹åŠ¿é¢„æµ‹**: é¢„æµ‹ç¢ç‰‡åŒ–å‘å±•è¶‹åŠ¿

### 4. å†…å­˜æ³„æ¼æ£€æµ‹å™¨ (Memory Leak Detector)
- **æ³„æ¼æ£€æµ‹**: æ£€æµ‹æ˜¾å­˜å’ŒPythonå†…å­˜æ³„æ¼
- **æ¥æºåˆ†æ**: åˆ†ææ½œåœ¨çš„æ³„æ¼æ¥æº
- **å¼•ç”¨è·Ÿè¸ª**: è·Ÿè¸ªå¯¹è±¡å¼•ç”¨å…³ç³»
- **ä¿®å¤å»ºè®®**: æä¾›å…·ä½“çš„ä¿®å¤å»ºè®®

### 5. åˆ†å¸ƒå¼å†…å­˜ç›‘æ§å™¨ (Distributed Memory Monitor)
- **å¤šèŠ‚ç‚¹åè°ƒ**: è·¨èŠ‚ç‚¹æ˜¾å­˜ä½¿ç”¨åŒæ­¥ç›‘æ§
- **è´Ÿè½½å‡è¡¡åˆ†æ**: åˆ†æå„èŠ‚ç‚¹é—´çš„å†…å­˜è´Ÿè½½å¹³è¡¡
- **ç“¶é¢ˆæ£€æµ‹**: è¯†åˆ«å†…å­˜ä½¿ç”¨ç“¶é¢ˆèŠ‚ç‚¹
- **é›†ç¾¤çº§OOMé¢„é˜²**: é›†ç¾¤çº§åˆ«çš„OOMé¢„é˜²å’Œæ¢å¤

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–
```bash
pip install numpy matplotlib psutil
```

### åŸºæœ¬ä½¿ç”¨

#### 1. å†…å­˜åˆ†æ
```bash
# ç›‘æ§60ç§’å¹¶ç”ŸæˆæŠ¥å‘Šå’Œå›¾è¡¨
python memory_debug_cli.py profile --duration 60 --output profile.json --plot

# æŒ‡å®šç‰¹å®šGPUè®¾å¤‡
python memory_debug_cli.py profile --devices 0 1 --duration 120
```

#### 2. OOMé£é™©æ£€æµ‹
```bash
# 85%é˜ˆå€¼æŒç»­ç›‘æ§
python memory_debug_cli.py oom --threshold 85 --monitor

# å®šæ—¶ç›‘æ§300ç§’
python memory_debug_cli.py oom --threshold 80 --duration 300 --output oom_report.json
```

#### 3. å†…å­˜æ³„æ¼æ£€æµ‹
```bash
# å¯ç”¨å¼•ç”¨è·Ÿè¸ªï¼Œ10MB/minæ³„æ¼é˜ˆå€¼
python memory_debug_cli.py leak --threshold 10 --enable-tracking --duration 600

# è¾“å‡ºè¯¦ç»†æŠ¥å‘Š
python memory_debug_cli.py leak --output leak_report.json --duration 300
```

#### 4. ç¢ç‰‡åˆ†æ
```bash
# åˆ†æç¢ç‰‡åŒ–å¹¶ç”Ÿæˆå›¾è¡¨
python memory_debug_cli.py fragment --duration 120 --plot --output fragment.json

# æŒç»­ç›‘æ§ç¢ç‰‡åŒ–è¶‹åŠ¿
python memory_debug_cli.py fragment --duration 300 --interval 5.0
```

#### 5. åˆ†å¸ƒå¼ç›‘æ§
```bash
# å¯åŠ¨masterèŠ‚ç‚¹
python memory_debug_cli.py distributed --role master --port 29500

# å¯åŠ¨workerèŠ‚ç‚¹ï¼ˆè¿æ¥åˆ°masterï¼‰
python memory_debug_cli.py distributed --role worker --master-host 192.168.1.100 --port 29500
```

### äº¤äº’å¼æ¨¡å¼
```bash
# è¿›å…¥äº¤äº’å¼è°ƒè¯•æ¨¡å¼
python memory_debug_cli.py interactive
```

## ğŸ“Š ä½¿ç”¨åœºæ™¯

### åœºæ™¯1ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­é¢‘ç¹OOM
```bash
# 1. é¦–å…ˆåˆ†æå½“å‰å†…å­˜ä½¿ç”¨æ¨¡å¼
python memory_debug_cli.py profile --duration 60 --plot

# 2. å¯åŠ¨OOMæ£€æµ‹ï¼Œè®¾ç½®è¾ƒä½é˜ˆå€¼è¿›è¡Œé¢„è­¦
python memory_debug_cli.py oom --threshold 75 --monitor

# 3. å¦‚æœæ€€ç–‘å†…å­˜æ³„æ¼ï¼Œè¿è¡Œæ³„æ¼æ£€æµ‹
python memory_debug_cli.py leak --enable-tracking --duration 600
```

### åœºæ™¯2ï¼šæ˜¾å­˜ç¢ç‰‡å¯¼è‡´çš„æ€§èƒ½ä¸‹é™
```bash
# 1. åˆ†æç¢ç‰‡åŒ–ç¨‹åº¦
python memory_debug_cli.py fragment --duration 180 --plot

# 2. ç›‘æ§ç¢ç‰‡åŒ–è¶‹åŠ¿
python memory_debug_cli.py fragment --duration 600 --interval 10
```

### åœºæ™¯3ï¼šåˆ†å¸ƒå¼è®­ç»ƒè´Ÿè½½ä¸å‡è¡¡
```bash
# åœ¨masterèŠ‚ç‚¹ä¸Šå¯åŠ¨
python memory_debug_cli.py distributed --role master --duration 600

# åœ¨workerèŠ‚ç‚¹ä¸Šå¯åŠ¨
python memory_debug_cli.py distributed --role worker --master-host <master_ip>
```

## ğŸ”§ é«˜çº§ç”¨æ³•

### ç¼–ç¨‹æ¥å£ä½¿ç”¨

```python
from tools.memory import (
    MemoryProfiler, 
    OOMDetector, 
    FragmentationAnalyzer,
    MemoryLeakDetector,
    DistributedMemoryMonitor
)

# åˆ›å»ºå†…å­˜åˆ†æå™¨
profiler = MemoryProfiler(sampling_interval=1.0)
profiler.start_monitoring()

# è¿è¡Œè®­ç»ƒä»£ç 
# ... your training code ...

# åœæ­¢ç›‘æ§å¹¶ç”ŸæˆæŠ¥å‘Š
profiler.stop_monitoring()
report = profiler.generate_report("training_memory_report.json")
```

### è‡ªå®šä¹‰å›è°ƒå‡½æ•°

```python
def custom_oom_callback(device_id, prediction):
    if prediction.risk_level.value == "critical":
        # æ‰§è¡Œç´§æ€¥æ“ä½œï¼Œå¦‚å‡å°‘batch size
        print(f"Critical OOM risk on GPU {device_id}! Taking action...")
        # torch.cuda.empty_cache()
        # reduce_batch_size()

detector = OOMDetector()
detector.add_warning_callback(custom_oom_callback)
detector.start_monitoring()
```

## ğŸ“ˆ æŠ¥å‘Šæ ¼å¼

### å†…å­˜åˆ†ææŠ¥å‘Šç¤ºä¾‹
```json
{
  "timestamp": "2025-06-23T10:30:00",
  "devices": {
    "0": {
      "current_memory": {
        "allocated": 8589934592,
        "free": 2147483648,
        "total": 10737418240,
        "utilization": 80.0
      },
      "peak_memory": 9663676416,
      "statistics": {
        "avg_utilization": 75.5,
        "max_utilization": 95.2,
        "avg_fragmentation": 15.3,
        "num_snapshots": 3600
      }
    }
  }
}
```

### OOMé£é™©æŠ¥å‘Šç¤ºä¾‹
```json
{
  "devices": {
    "0": {
      "risk_assessment": {
        "risk_level": "high",
        "confidence": 0.8,
        "current_usage_percent": 88.5,
        "growth_rate_mb_per_sec": 12.3,
        "predicted_oom_time_seconds": 45,
        "recommendation": "Reduce batch size immediately"
      }
    }
  }
}
```

## âš¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### æ˜¾å­˜ä¼˜åŒ–ç­–ç•¥
1. **åŸºäºåˆ†æç»“æœè°ƒæ•´batch size**
2. **ä½¿ç”¨gradient checkpointingå‡å°‘å³°å€¼å†…å­˜**
3. **å®šæœŸæ¸…ç†CUDAç¼“å­˜**: `torch.cuda.empty_cache()`
4. **ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ**: å‡å°‘å†…å­˜ä½¿ç”¨
5. **ä¼˜åŒ–æ•°æ®åŠ è½½**: é¿å…æ•°æ®é¢„å¤„ç†å ç”¨è¿‡å¤šå†…å­˜

### ç¢ç‰‡åŒ–ä¼˜åŒ–
1. **é¿å…é¢‘ç¹çš„å°å—åˆ†é…é‡Šæ”¾**
2. **ä½¿ç”¨å†…å­˜æ± **: é¢„åˆ†é…å¤§å—å†…å­˜
3. **å®šæœŸç¢ç‰‡æ•´ç†**: åœ¨åˆé€‚çš„æ—¶æœºæ¸…ç†ç¼“å­˜
4. **ä¼˜åŒ–å¼ é‡ç”Ÿå‘½å‘¨æœŸ**: åŠæ—¶é‡Šæ”¾ä¸éœ€è¦çš„å¼ é‡

### åˆ†å¸ƒå¼ä¼˜åŒ–
1. **è´Ÿè½½å‡è¡¡**: æ ¹æ®ç›‘æ§ç»“æœè°ƒæ•´å„èŠ‚ç‚¹è´Ÿè½½
2. **åŒæ­¥ä¼˜åŒ–**: é¿å…å†…å­˜ä½¿ç”¨ä¸å‡è¡¡å¯¼è‡´çš„åŒæ­¥ç­‰å¾…
3. **æ•…éšœæ¢å¤**: åŸºäºç›‘æ§æ•°æ®å®ç°æ™ºèƒ½æ•…éšœæ¢å¤

## ğŸ” æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### 1. "nvidia-smi command not found"
- ç¡®ä¿å®‰è£…äº†NVIDIAé©±åŠ¨
- æ£€æŸ¥PATHç¯å¢ƒå˜é‡æ˜¯å¦åŒ…å«nvidia-smi

#### 2. ç›‘æ§æ•°æ®ä¸å‡†ç¡®
- æ£€æŸ¥GPUè®¾å¤‡æ˜¯å¦æ­£ç¡®è¯†åˆ«
- ç¡®è®¤ç›‘æ§è¿›ç¨‹æœ‰è¶³å¤Ÿæƒé™
- éªŒè¯é‡‡æ ·é—´éš”è®¾ç½®æ˜¯å¦åˆç†

#### 3. åˆ†å¸ƒå¼ç›‘æ§è¿æ¥å¤±è´¥
- æ£€æŸ¥ç½‘ç»œconnectivity
- ç¡®è®¤é˜²ç«å¢™è®¾ç½®
- éªŒè¯ç«¯å£æ˜¯å¦è¢«å ç”¨

#### 4. å†…å­˜æ³„æ¼è¯¯æŠ¥
- è°ƒæ•´æ³„æ¼æ£€æµ‹é˜ˆå€¼
- æ£€æŸ¥æ˜¯å¦æœ‰æ­£å¸¸çš„å†…å­˜å¢é•¿ï¼ˆå¦‚æ¨¡å‹æƒé‡æ›´æ–°ï¼‰
- å¯ç”¨å¼•ç”¨è·Ÿè¸ªè·å–è¯¦ç»†ä¿¡æ¯

## ğŸ“ æœ€ä½³å®è·µ

### 1. ç›‘æ§ç­–ç•¥
- **å¼€å‘é˜¶æ®µ**: ä½¿ç”¨è¾ƒçŸ­çš„é‡‡æ ·é—´éš”(1-2ç§’)è¿›è¡Œè¯¦ç»†åˆ†æ
- **ç”Ÿäº§ç¯å¢ƒ**: ä½¿ç”¨è¾ƒé•¿çš„é‡‡æ ·é—´éš”(5-10ç§’)é™ä½ç›‘æ§å¼€é”€
- **å…³é”®è®­ç»ƒ**: å¯ç”¨æ‰€æœ‰ç›‘æ§å·¥å…·è¿›è¡Œå…¨é¢åˆ†æ

### 2. æŠ¥å‘Šç®¡ç†
- å®šæœŸä¿å­˜ç›‘æ§æŠ¥å‘Šç”¨äºè¶‹åŠ¿åˆ†æ
- å»ºç«‹æŠ¥å‘Šå½’æ¡£æœºåˆ¶
- è®¾ç½®è‡ªåŠ¨åŒ–æŠ¥å‘Šç”Ÿæˆ

### 3. å‘Šè­¦é…ç½®
- æ ¹æ®æ¨¡å‹å’Œç¡¬ä»¶ç‰¹ç‚¹è°ƒæ•´å‘Šè­¦é˜ˆå€¼
- è®¾ç½®å¤šçº§å‘Šè­¦æœºåˆ¶
- é›†æˆåˆ°ç°æœ‰çš„ç›‘æ§ç³»ç»Ÿ

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç å’Œå»ºè®®ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Fork this repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ä¸Tiny-Torchç›¸åŒçš„è®¸å¯è¯ã€‚

## ğŸ™‹â€â™‚ï¸ æ”¯æŒ

å¦‚æœé‡åˆ°é—®é¢˜æˆ–æœ‰å»ºè®®ï¼Œè¯·ï¼š
1. æŸ¥çœ‹æœ¬æ–‡æ¡£çš„æ•…éšœæ’æŸ¥éƒ¨åˆ†
2. åœ¨GitHubä¸Šæäº¤Issue
3. è”ç³»é¡¹ç›®ç»´æŠ¤è€…

---

**æ³¨æ„**: è¿™äº›å·¥å…·ä¸»è¦ç”¨äºè°ƒè¯•å’Œåˆ†æï¼Œåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨æ—¶è¯·è¯„ä¼°æ€§èƒ½å½±å“ã€‚
